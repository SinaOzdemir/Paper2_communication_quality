###############################################################
# Project:    EU Tweet
# Task:       Visual descriptive overview of EU Tweet Sample
#             against benchmark samples
# Author:     Christian Rauh (31.05.2021)
##############################################################

# Packages ####
library(tidyverse) # 1.3.0
library(patchwork) # 1.1.1
library(ggridges) # 0.5.2
library(ggtext) # 0.1.1
library(scales) # 1.1.1
library(stargazer) # 5.2.2


# Prepare the data ####

# As generated by 3_AnalyticDataSet.R and preceeding steps
tweets <- read_rds("./data/AnalyticData_AllSamples.RDS")

# Filter some accounts
tweets <- tweets %>% 
  filter(screen_name != "HMRCcustomers") %>%  # Customer support account
  filter(screen_name != "DVLAgovuk") %>%      # Online service account of the Driver&Vehicle licensing agency
  filter(screen_name != "nsandihelp")         # A help desk (what is this org anyway?)


# Add personal institutional distinction for the IO sample
# Coding by CR and KBH consistent
iopersonal <- read.csv2("./analysis_data/IO_account_coding_CR.csv") %>% 
  filter(personal == 1) 
iopersonal <- iopersonal[,1] # Screen names to atomic vector
tweets$tweetsample[tweets$screen_name %in% iopersonal] <- "IO (pers. account)"
tweets$tweetsample[tweets$tweetsample == "IO"] <- "IO (inst. account)"
rm(iopersonal)

# Clean group variables (for plotting)
tweets$group1 <- tweets$tweetsample %>% 
  str_replace(" ", "\n") %>% ## Add line breaks
  factor(levels = c("EU\n(inst. account)", # Order as factor
                    "EU\n(pers. account)",
                    "UK\n(inst. account)",
                    "UK\n(pers. account)",
                    "IO\n(inst. account)",
                    "IO\n(pers. account)",
                    "Random\nTweets")) %>% 
  fct_rev() # Reverse, so that EU always comes out on top (for horizontal plots, reverse in ggplot call)

tweets$group2 <- tweets$tweetsample %>% 
  str_remove(" .*$") %>% # Remove pers/inst distinction (for color coding later)
  factor(levels = c("EU", # Order as factor
                    "UK",
                    "IO",
                    "Random")) %>% 
  fct_rev() # Reverse, so that EU alsways comes out on top

# Mark group of benchmark samples separately
tweets$benchmark <- !str_detect(tweets$tweetsample, "EU ")

# Retain copy of screen_names / sample assocs
# for easy labelling aggregated data downstream
account.types <- tweets %>% 
  select(screen_name, group1, group2, benchmark) %>% 
  unique()
account.types <- account.types %>% 
  filter(!(screen_name == "BaldwinMatthew_" & group2 == "Random")) # Crazy coincidence!
sum(duplicated(account.types$screen_name))

# # Nicer group names for plotting
# tweets$group <- tweets$tweetsample
# tweets$group[tweets$group == "EU (inst. account)"] <- "EU supranational\n(institutional accounts)"
# tweets$group[tweets$group == "EU (pers. account)"] <- "EU supranational\n(personal accounts)"
# tweets$group[tweets$group == "IO"] <- "International Organisations\n(institutional accounts)"
# tweets$group[tweets$group == "UK"] <- "UK government accounts"
# tweets$group[tweets$group == "TWT"] <- "Random Tweets"
# tweets$group <- factor(tweets$group, 
#                        levels = c("Random Tweets",
#                                   "UK government accounts",
#                                   "International Organisations\n(institutional accounts)",
#                                   "EU supranational\n(personal accounts)",
#                                   "EU supranational\n(institutional accounts)"))


# Number of available tweets and accounts per sample
cases <- rbind(as.data.frame(table(tweets$tweetsample)),
               as.data.frame(table(tweets$group2))) %>% 
  rename(Sample = 1,
         Tweets = 2) %>% 
  mutate(Sample = as.character(Sample))

cases$Accounts <- NA
for (i in 1:nrow(cases)) {
  if (i <= 7){
    cases$Accounts[i] <- length(unique(tweets$screen_name[tweets$tweetsample == cases$Sample[i]]))
  } else {
    cases$Accounts[i] <- length(unique(tweets$screen_name[str_detect(tweets$tweetsample, cases$Sample[i])]))
  }
}
writeLines(stargazer(cases, type = "html", summary = F, rownames = F), 
           "./tables/TweetSampleOverview.html")
rm(cases)


# Correct some coding nuissances
# Probably correct downstream!
tweets$nexturl[is.na(tweets$nexturl)] <- 0 # there were just none
tweets$nphotos[is.na(tweets$nphotos)] <- 0 # there were just none
tweets$nvideos[is.na(tweets$nvideos)] <- 0 # there were just none
tweets$ntube[is.na(tweets$ntube)] <- 0 # there were just none
tweets$lsd[!tweets$en_av] <- NA # If there was no english text, sentiment score is missing, not 0

# Mark original (self-authored) tweets
# excluding retweets and quotes
tweets$original <- tweets$is_retweet == F & tweets$is_quote == F
sum(tweets$original)

# Time markers
tweets$month <- str_extract(as.character(tweets$day), "[0-9]{4}-[0-9]{2}")


# Sample for testing purpose
# tweets <- tweets %>% sample_n(10000)



# Overarching ggplot params ####

theme_set(theme_light() +
            theme(legend.position = "none",
                  axis.text = element_text(color = "black"),
                  plot.title = element_text(size=10),
                  panel.grid.minor = element_blank()))

benchmarkcolors <- c("#003399", "#FFCC00") # EU, all the way down ...
benchmarkshapes <- c(18, 19)



# Daily tweet output ####

# Couple of things to note here:
# We want daily output by type and individual (!) account
# But not all accounts tweet daily (but for averaging we need the zero tweet days as well)
# In addition, not all accounts existed fro the same date range, we do not want zeos if the account actually dinh't exist that day
# Solution: Before aggregating, loop through the individual accounts 
# and fill the date range between their first and their last tweet in our sample

# All of this is not meaningful for our random tweet sample, of course

df <- tweets %>% 
  filter(tweetsample != "Random Tweets") %>% 
  select(screen_name, day) 

daily <- data.frame() # Target data frame

# Create full date range by account
for (account in unique(df$screen_name)) {
  
  # All obs for one account
  current <- df %>% 
    filter(screen_name == account) %>% 
    group_by(day) %>% 
    summarise(tweets = n())
  
  # Maximum data range
  days <- seq.Date(min(current$day), max(current$day), by = "days") %>% 
    as.data.frame() %>% 
    rename(day = 1)
  
  # Join date range and counts
  days <- days %>% 
    left_join(current, by = "day") %>% 
    mutate(screen_name = account)
  
  # Append to target DF
  daily <- rbind(daily, days)
}
rm(days)
rm(current)


# Indicate days with zero tweets as such
daily$tweets[is.na(daily$tweets)] <- 0


# Average tweet output by account
avid.tweeters <- daily %>% 
  group_by(screen_name) %>% 
  summarise(mean.daily.tweets = round(mean(tweets), 2))

avid.tweeters <- avid.tweeters %>% 
  left_join(account.types, by = "screen_name") %>% 
  arrange(desc(group1), desc(mean.daily.tweets))

write_rds(avid.tweeters, "./analysis_data/AverageDailyTweetsByAccount.RDS")

# Most avid and most lazy EU tweeters
eutweeters <- avid.tweeters %>% 
  filter(group2 == "EU") %>% 
  arrange(desc(mean.daily.tweets))

head(eutweeters, 10)
tail(eutweeters, 10)

# SD across account by sample
avid.tweeters %>% group_by(group2) %>% summarise(sd(mean.daily.tweets))

rm(eutweeters)
rm(avid.tweeters)


# Add group info to daily tweet data
daily <- daily %>% 
  left_join(account.types, by = "screen_name")


# Export for later INSPECTION!
write_rds(daily, "./analysis_data/DailyTweetsByAccount.RDS")
# Some peak days - INSPECT!
# hist(daily$tweets)
# test <- daily %>% filter(tweets > 100)


# Daily average from EU accounts over time
eu.daily <- daily %>% filter(group2 == "EU")

t.breaks <- eu.daily[,1] %>% # Labelling breaks
  unique() %>% 
  as.character() %>% 
  sort()
t.breaks <- t.breaks[str_detect(t.breaks, "-01-01")] # First of January
t.labels <- t.breaks %>% str_extract("[0-9]{4}") # Years for labelling

pl.daily.eu <- # The plot
  ggplot(eu.daily, aes(x = as.character(day), y = tweets, group = 1))+
  # geom_point()+
  # stat_summary(geom = "line", fun = mean)+
  stat_smooth(color = "#003399")+
  # geom_rug(sides = "b", alpha = .2)+
  scale_y_continuous(breaks = seq(0,3.5,0.5))+
  coord_cartesian(ylim = c(0, 3.7))+ 
  scale_x_discrete(breaks = t.breaks, labels = t.labels) +
  labs(title = "Average daily number of tweets\nby supranational EU accounts over time (smoothed)",
       x= "", y = "")+
  theme(axis.text.x = element_text(angle = 90, vjust = .5))


# Daily n of tweets in comparison

pl.daily.comp <-
  ggplot(daily, aes(x = reorder(group1, desc(group1)), y = tweets, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot")+
  scale_color_manual(values = c("#FFCC00", "darkred", "#003399"))+
  facet_grid(.~ reorder(group2, desc(group2)), scales = "free_x")+
  scale_y_continuous(breaks = seq(0,3.5,0.5))+
  coord_cartesian(ylim = c(0, 3.7))+ 
  labs(title = "Average daily number of tweets\nper account and actor type",
       x= "", y = "")+
  theme(axis.text.x = element_text(angle = 90, vjust = .5))


# Combine and export daily output plots

pl.daily <- 
  pl.daily.eu + pl.daily.comp  + 
  plot_layout(widths = c(2, 1))

ggsave("./plots/DescriptiveOverview/DailyTweets.png", plot = pl.daily, width = 20, height = 10, units = "cm")

# IDEAS:
# Correlate/Scatter daily/monthly n of press releases (Rauh 2021) and legislative output (Rauh 2020)
# with daily tweets of EU_Commission handle - first one informs abiut overarching Comm startegy, second oe about responsibility clarification



# Media usage ####
# in orignal (self-authored) tweets only

# Pictures
pl.photos <-
  ggplot(tweets[tweets$original, ], aes(x = as.integer(nphotos>0), y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  scale_x_continuous(labels = label_percent(accuracy = 1L))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Share of tweets with embedded picture",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))

# Videos
tweets$video <- (tweets$nvideos + tweets$ntube)>0 # Embeded and link-embedded videos
pl.videos <-
  ggplot(tweets[tweets$original, ], aes(x = as.integer(video), y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  scale_x_continuous(labels = label_percent(accuracy = 1L))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Share of tweets with embedded video",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))


# Emojis
pl.emojis <-
  ggplot(tweets[tweets$original, ], aes(x = emojicount, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Emojis / special symbols per tweet",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))

# External urls
pl.urls <-
  ggplot(tweets[tweets$original, ], aes(x = nexturl, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "External links per tweet",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))

# Combined Plot
pl.media <-
  (pl.photos+pl.videos) / (pl.emojis+pl.urls)+
  plot_annotation(caption = "Only original tweets (excluding re-tweets and quotes).")
ggsave("./plots/DescriptiveOverview/MediaUsage.png", plot = pl.media, width = 24, height = 20, units = "cm")




# Language ####

# Get info on used languages
eu <- read_rds("./data/corpii/EU_corpus_cleaned.RDS") %>% 
  select(tweetlanguage, tweetlanguages, texten)

(sum(str_count(eu$tweetlanguages, "en"))/nrow(eu))*100 # Share of tweets with at least one English sentence
(sum(eu$tweetlanguages == "en")/nrow(eu))*100 # Share of tweets with only english sentences

langs <- paste(eu$tweetlanguages, collapse = ", ") %>%  # All detected languages
  str_split(", ") %>% # Atomic representation
  as.data.frame() %>% 
  rename(language = 1) %>% 
  filter(language != "") %>% 
  group_by(language) %>% 
  summarise(count = n()) %>% 
  mutate(share = round((count/nrow(eu))*100, 2)) %>% # Share of tweets including respective language
  arrange(desc(share))

head(langs, 10)

rm(eu)
rm(langs)
gc()


# Understandability 

pl.flesch <-
  ggplot(tweets[tweets$original, ], aes(x = flesch, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Flesch\nreading ease score",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"),
        strip.background = element_blank(),
        strip.text.x = element_blank())

pl.familiarity <-
  ggplot(tweets[tweets$original, ], aes(x = familiarity, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Familiarity of vocabulary\n(Google books freq.)",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))+
  theme(axis.text.x = element_text(angle = 90, vjust = .5),
        strip.background = element_blank(),
        strip.text.x = element_blank())

pl.verbal <-
  ggplot(tweets[tweets$original, ], aes(x = verbal, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Verb-to-noun\nratio",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"),
        strip.background = element_blank(),
        strip.text.x = element_blank())

pl.sentiment <-
  ggplot(tweets[tweets$original, ], aes(x = lsd, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("grey30", "#FFCC00", "darkred", "#003399"))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Sentiment (LSD)",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"),
        strip.background = element_blank(),
        strip.text.x = element_blank())

# Combined plot
# pl.language <-
#   (pl.flesch + pl.familiarity) / (pl.verbal + pl.sentiment) +
#   plot_annotation(caption = "Only original tweets (excluding re-tweets and quotes) with English-language content.")

pl.language <-
  (pl.flesch + pl.familiarity + pl.verbal) +
  plot_annotation(caption = "Only original tweets (excluding re-tweets and quotes) with English-language content.")
  
ggsave("./plots/DescriptiveOverview/Language.png", plot = pl.language, width = 22, height = 11, units = "cm")







# Engagement ####
#################

# Hearts
pl.favs <-
  ggplot(df, aes(y = favorite_count, x = month, color = account_type, group = account_type))+
  # stat_summary(geom = "pointrange", fun.data = "mean_cl_boot") +
  stat_summary(geom = "line", fun = "mean", na.rm = T)+
  # geom_point()+
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_color_manual(values = accountcolors)+
  labs(title= "Average number of favorites per tweet and month",
       color = "",
       x= "", y = "")+
  theme(legend.position = c(0.2,.88),
        legend.background = element_blank())

# Retweets
pl.rets <- 
  ggplot(df, aes(y = retweet_count, x = month, color = account_type, group = account_type))+
  # stat_summary(geom = "pointrange", fun.data = "mean_cl_boot") +
  stat_summary(geom = "line", fun = "mean", na.rm = T)+
  # geom_point()+
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_color_manual(values = accountcolors)+
  labs(title= "Average number of retweets per tweet and month",
       color = "",
       x= "", y = "")    

# Combine
pl.engagement <-
  pl.favs/pl.rets +
  plot_annotation(title = "How much do users engage with tweets from supranational actors?",
                  caption = "Note that both favorite and retweet counts follow an extremely right-skewed distribution\nand are subject to strong individual outliers.",
                  theme = theme(plot.title = element_text(hjust = 0.5, 
                                                          size = 14, face = "bold")))

ggsave("./plots/DescriptiveOverview/Engagement.png", width = 20, height = 15, units = "cm")


# Multivariate including UK & IO sample (which requires follower counts!)
# bc language quality varies her and we could see whether engegement does so likewise ...


# # Analyse daily tweet volume ####
# 
# # Daily number of tweets in sample
# days <- corpus %>% 
#   mutate(day = str_trim(str_extract(created_at, ".*^? "))) %>% 
#   select(day) %>% 
#   group_by(day) %>% 
#   summarise(count = n())
# 
# # Descriptives
# min(days$day)  
# max(days$day)
# mean(days$count)
# 
# # Time series
# dates <- seq(as.Date(min(days$day)), as.Date(max(days$day)), by = "days") %>% # all dates within range
#   as.data.frame() %>% 
#   rename(day = 1) %>% 
#   mutate(day = as.character(day))
# 
# dates <- left_join(dates, days, by = "day")
# dates$count[is.na(dates$count)] <- 0
# 
# breaks <- dates %>%  # Breaks for x-axis
#   filter(str_detect(day, "01-01$")) %>% # 1st January
#   select(day)
# breaks <- as.character(breaks[,1])
# labels <- str_remove(breaks, "-.*$") %>% unique() # Year only
# 
# ggplot(dates, aes(x= day, y= count)) + 
#   geom_col()+
#   scale_x_discrete(breaks = breaks, labels = labels)+
#   labs(title = "Daily volume of tweets in EUtweet sample",
#        subtitle = "117 verified accounts of supranational persons, offices, and institutions",
#        x = "\nDay",
#        y = "Number of tweets\n")+
#   theme_bw()+
#   theme()
# 
# ggsave("./plots/TweetVolumeDaily.png", width = 16, height = 10, units = "cm")
# 
# # Weekday
# old.setting <- Sys.getlocale("LC_TIME") # Store current time setting of locale
# Sys.setlocale("LC_TIME","English_United States.1252") # switch to English
# wdays <- dates %>% 
#   mutate(weekday = weekdays(as.Date(day))) %>% 
#   group_by(weekday) %>% 
#   summarise(mean = mean(count))
# Sys.setlocale("LC_TIME", old.setting) # Reinstate old LC Time setting
# wdays$weekday <- factor(wdays$weekday, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
# 
# ggplot(wdays, aes(x= mean, y= fct_rev(weekday))) + 
#   geom_col()+
#   labs(title = "Tweets per weekday in EUtweet sample",
#        subtitle = "117 verified accounts of supranational persons, offices, and institutions",
#        x = "\nAverage number of tweets\n(2009-03-13/2021-03-14) ",
#        y = "")+
#   theme_bw()+
#   theme()
# 
# ggsave("./plots/TweetVolumeWeekday.png", width = 16, height = 10, units = "cm")





# Tweet output (OLD!) ####

# # Monthly number of supranational tweets # 
# eumonthly <- tweets %>% 
#   filter(!benchmark) %>% # Only the EU Tweets
#   group_by(month) %>% 
#   summarise(count = n()) %>% 
#   arrange(month)
# 
# # Ensure full range of months
# months <- seq.Date(from = min(tweets$day[!tweets$benchmark]), 
#                    to = max(tweets$day[!tweets$benchmark]), 
#                    by = "days") %>% 
#   as.character() %>% 
#   str_remove("-[0-9]{2}$") %>% 
#   unique() %>% 
#   as.data.frame() %>% 
#   rename(month = 1)
# 
# # Plotting markers
# t.breaks <- months %>% 
#   filter(str_detect(month, "-01")) # Only Januaries
# t.breaks <- t.breaks[,1] # Atomic vector
# t.labels <- str_remove(t.breaks, "-01")  
# 
# # Join series
# eumonthly <- left_join(months, eumonthly, by = "month")
# 
# # Plot time series
# pl.output.month <- 
#   ggplot(eumonthly, aes(x=month, y = count, group = 1))+
#   geom_bar(stat = "identity", width = .5, fill = "#003399", color = "#003399")+
#   # geom_line()+
#   scale_x_discrete(breaks = t.breaks, labels = t.labels)+
#   labs(title = "Number of tweets by supranational EU actors per month ",
#        x = "",
#        y = "")
# 
# 
# # Daily number of tweets #
# # NOT SURE: DOES THIS NEED TO BE GROUPED BY ACCOUNTS FIRST?
# # SO AS TO SHOW VARIATION WITHIN GROUP?
# daily <- tweets %>% 
#   filter(!str_detect(tweetsample, "Random")) %>% 
#   group_by(group1, day) %>% 
#   summarise(count = n()) %>% 
#   mutate(benchmark = !str_detect(as.character(group1), "^EU"))
# pl.output.daily <-
#   ggplot(daily, aes(x = count, y = group1, color = benchmark, shape = benchmark)) +
#   stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
#   # coord_flip() +
#   scale_color_manual(values = benchmarkcolors)+
#   scale_shape_manual(values = benchmarkshapes)+
#   labs(title = "Average daily number of tweets",
#        x= "",
#        y= "")
# # + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))
# 
# # Number of words per tweet #
# pl.output.words <-
#   ggplot(tweets, aes(x = ntoken, y = group, color = benchmark, shape = benchmark)) +
#   stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
#   # coord_flip()+
#   scale_color_manual(values = benchmarkcolors)+
#   scale_shape_manual(values = benchmarkshapes)+
#   # scale_y_discrete(limits = rev(levels(group)))+
#   labs(title = "Average tweet length (words)",
#        x= "",
#        y= "")  # subtitle = "English language tweets only"
# # + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))
# 
# # Combine output plots
# 
# # pl.output <- pl.output.month / (pl.output.daily + pl.output.words) + 
# #   plot_annotation(title = "How much do supranational actors tweet?",
# #                   theme = theme(plot.title = element_text(hjust = 0, 
# #                                                           size = 14, face = "bold")))+
# #   plot_layout(heights = c(2, 1))
# 
# 
# pl.output <- pl.output.month + pl.output.daily  + 
#   # plot_annotation(title = "How much do supranational actors tweet?",
#   #                 theme = theme(plot.title = element_text(hjust = .5, 
#   #                                                         size = 14, face = "bold")))+
#   plot_layout(widths = c(2.5, 1))
# 
# ggsave("./plots/DescriptiveOverview/Output.png", plot = pl.output, width = 30, height = 12, units = "cm")
