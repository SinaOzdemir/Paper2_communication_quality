########################################################
# Project:    EU Tweet
# Task:       Analyse user engagement 
# Author:     Christian Rauh (24.06.2021)
########################################################


# Packages #####
library(tidyverse) # 1.3.0
library(patchwork) # 1.1.1
library(scales) # 1.1.1
library(corrgram) 
library(coefplot)
library(margins)
library(kableExtra) # 1.3.1
library(utf8)




# Prepare data ####

# As generated by 3_AnalyticDataSet.R and preceeding steps
# w/out random tweetes
tweets <- read_rds("./data/AnalyticData_AllSamples.RDS") %>% 
  filter(!str_detect(tweetsample, "Random "))

# Filter some accounts
tweets <- tweets %>% 
  filter(screen_name != "HMRCcustomers") %>%  # Customer support account
  filter(screen_name != "DVLAgovuk") %>%      # Online service account of the Driver&Vehicle licensing agency
  filter(screen_name != "nsandihelp")         # A help desk (what is this org anyway?)


# Add personal institutional distinction for the IO sample
# Coding by CR and KBH consistent
iopersonal <- read.csv2("./analysis_data/IO_account_coding_CR.csv") %>% 
  filter(personal == 1) 
iopersonal <- iopersonal[,1] # Screen names to atomic vector
tweets$tweetsample[tweets$screen_name %in% iopersonal] <- "IO (pers. account)"
tweets$tweetsample[tweets$tweetsample == "IO"] <- "IO (inst. account)"
rm(iopersonal)

# Clean group variables (for plotting)
tweets$group1 <- tweets$tweetsample %>% 
  str_replace(" ", "\n") %>% ## Add line breaks
  factor(levels = c("EU\n(inst. account)", # Order as factor
                    "EU\n(pers. account)",
                    "UK\n(inst. account)",
                    "UK\n(pers. account)",
                    "IO\n(inst. account)",
                    "IO\n(pers. account)",
                    "Random\nTweets")) %>% 
  fct_rev() # Reverse, so that EU always comes out on top (for horizontal plots, reverse in ggplot call)

tweets$group2 <- tweets$tweetsample %>% 
  str_remove(" .*$") %>% # Remove pers/inst distinction (for color coding later)
  factor(levels = c("EU", # Order as factor
                    "UK",
                    "IO",
                    "Random")) %>% 
  fct_rev() # Reverse, so that EU alsways comes out on top

# Mark group of benchmark samples separately
tweets$benchmark <- !str_detect(tweets$tweetsample, "EU ")

# Retain copy of screen_names / sample assocs
# for easy labelling aggregated data downstream
account.types <- tweets %>% 
  select(screen_name, group1, group2, benchmark) %>% 
  unique()
account.types <- account.types %>% 
  filter(!(screen_name == "BaldwinMatthew_" & group2 == "Random")) # Crazy coincidence!
sum(duplicated(account.types$screen_name))


# Correct some coding nuissances
# Probably correct downstream!
tweets$nexturl[is.na(tweets$nexturl)] <- 0 # there were just none
tweets$nphotos[is.na(tweets$nphotos)] <- 0 # there were just none
tweets$nvideos[is.na(tweets$nvideos)] <- 0 # there were just none
tweets$ntube[is.na(tweets$ntube)] <- 0 # there were just none
tweets$lsd[!tweets$en_av] <- NA # If there was no english text, sentiment score is missing, not 0

# Mark original (self-authored) tweets
# excluding retweets and quotes
tweets$original <- tweets$is_retweet == F & tweets$is_quote == F
sum(tweets$original)

# Filter original tweets
# All engagement analysis only on self-authored messages
tweets <- tweets %>% filter(original)

# Time markers
tweets$month <- str_extract(as.character(tweets$day), "[0-9]{4}-[0-9]{2}")



# Add follower  ####

fcounts <- rbind(read_rds("./analysis_data/FollowerCountsInterpolated_EU.RDS"),
                 read_rds("./analysis_data/FollowerCountsInterpolated_IO.RDS"),
                 read_rds("./analysis_data/FollowerCountsInterpolated_UK.RDS")) %>% 
  select(-follower_count) %>% 
  rename(day = date,
         ifollowers = follower_count_interpolated)

tweets <- tweets %>% left_join(fcounts, by = c("screen_name", "day"))
sum(is.na(tweets$ifollowers))



# Normalize user engagement allong follower count ####

tweets$ifollowers[tweets$ifollowers == 0] <- 1 # Prevent infinite reatios, we interpolated from 0

tweets$like_ratio <- (tweets$like_count/tweets$ifollowers)*100
tweets$retweet_ratio <- (tweets$retweet_count/tweets$ifollowers)*100
tweets$quote_ratio <- (tweets$quote_count/tweets$ifollowers)*100
tweets$reply_ratio <- (tweets$reply_count/tweets$ifollowers)*100

tweets <- tweets %>% 
  mutate(enga_ratio = like_ratio + retweet_ratio + quote_ratio + reply_ratio) # Overall engagement rate


# Overarching ggplot params ####
theme_set(theme_light() +
            theme(legend.position = "none",
                  axis.text = element_text(color = "black"),
                  plot.title = element_text(size=10, face = "bold"),
                  plot.subtitle = element_text(size=10),
                  panel.grid.minor = element_blank()))



# EU follower counts ####

# Monthly breaks/labels
t.breaks <- tweets[tweets$group2 == "EU", "month"][,1] %>% # Labelling breaks
  unique() %>% 
  arrange(month) 
t.breaks <- t.breaks[[1]] 
t.breaks <- t.breaks[str_detect(t.breaks, "-01")] # Januaries
t.labels <- t.breaks %>% str_extract("[0-9]{4}") # Years for labelling

# Eu follower counts 
eufollowers <- tweets %>% 
  filter(group2 == "EU") %>% 
  group_by(month) %>% 
  summarise(maxf = max(ifollowers, na.rm = T),
            meanf = round(mean(ifollowers, na.rm = T),0),
            minf = min(ifollowers, na.rm = T),
            medianf = median(ifollowers, na.rm = T))

# Plot
pl.followers <- 
  ggplot(eufollowers, aes(x=month, group = 1)) + 
  geom_line(aes(y=maxf), color = "#003399")+
  geom_line(aes(y=medianf), color = "#003399")+
  geom_line(aes(y=meanf), color = "#003399")+
  annotate(geom = "label", x = 140, y = eufollowers$maxf[140], label = "Max", color = "#003399")+
  annotate(geom = "label", x = 140, y = eufollowers$meanf[140], label = "Mean", color = "#003399")+
  annotate(geom = "label", x = 140, y = eufollowers$medianf[140], label = "Median", color = "#003399")+
  labs(title = "Number of followers of supranational EU accounts",
       x= "", y = "")+
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_y_continuous(breaks = seq(0, 1500000, 100000),label=comma)

ggsave("./plots/UserEngagement/EUfollowersTime.png", plot = pl.followers, width = 24, height = 10, units = "cm")
  

# Followers by account (max)

accountfollowers <- tweets %>% 
  filter(group2 == "EU") %>% 
  group_by(screen_name) %>% 
  summarise(maxf = max(ifollowers, na.rm = T),
            personal = mean(str_detect(group1, "pers. account"))) %>% 
  arrange(desc(maxf))

head(accountfollowers, 10)
tail(accountfollowers, 10)

# Personal vs institutional accounts
t.test(accountfollowers$maxf[accountfollowers$personal == 1], accountfollowers$maxf[accountfollowers$personal == 0])


# Snapshot availability
eusnaps <- read_rds("./analysis_data/EU-snapshots.RDS")
eusnaps[eusnaps$snapshots == max(eusnaps$snapshots), ]
eusnaps[eusnaps$snapshots == min(eusnaps$snapshots[eusnaps$snapshots != 0]), ]
sum(eusnaps$snapshots == 0)



# Descriptive analysis of user engagement ####

# The most viral supranational tweets

hist(tweets$enga_ratio[tweets$group2 == "EU"])

viral <- tweets %>% 
  filter(group2 == "EU") %>% 
  select(c(id, day, screen_name, ifollowers, enga_ratio, 
           like_count, like_ratio, retweet_count, retweet_ratio,
           quote_count, quote_ratio, reply_count, reply_ratio)) %>% 
  arrange(desc(enga_ratio)) %>% 
  head(10)

ttexts <- read_rds("./data/corpii/EU_corpus_cleaned.RDS") %>% 
  select(id, text) %>% 
  filter(id %in% viral$id)

viral <- viral %>%  left_join(ttexts, by = "id")

# Hmpf ... 'hello world' tweets - entirely driven by underestimating the follower count
# We need to filter - only when and after snapshots are available



# Filter sample along snapshot dates

# Snapshot info
snapav <- rbind(read_rds("./analysis_data/FollowerCountsInterpolated_EU.RDS"), # Follower counts
                read_rds("./analysis_data/FollowerCountsInterpolated_IO.RDS"),
                read_rds("./analysis_data/FollowerCountsInterpolated_UK.RDS")) %>%
  filter(follower_count != 0 & # Drop obs without follower count measurement
           !is.na(follower_count)) %>% 
  select(-follower_count_interpolated) %>% 
  group_by(screen_name) %>% 
  summarise(earliest = min(date), # Earliest snapshot by account
            snaps = n()) %>% # Number of snaps by account
  filter(snaps > 1) # At least two snapshots need to be available
  
# Filter users
tweets2 <- tweets %>% filter(screen_name %in% snapav$screen_name)

# Filter tweets by earliest snapshot
df.enga <- data.frame()

for (account in unique(tweets2$screen_name)) {
  
  # Progres
  print(account)
  
  # Select and filter tweets
  dat <- tweets2 %>% 
    filter(screen_name == account) %>% # All Tweets from that account
    filter(day >= snapav$earliest[snapav$screen_name == account]) # Only from ealiest snapshot date
  
  # Append to target
  df.enga <- rbind(df.enga, dat)
}

rm(dat)
gc()


# The most viral supranational tweets in that reduced sample

hist(df.enga$enga_ratio[df.enga$group2 == "EU"])

viral <- df.enga %>% 
  filter(group2 == "EU") %>% 
  select(c(id, day, screen_name, ifollowers, enga_ratio, 
           like_count, like_ratio, retweet_count, retweet_ratio,
           quote_count, quote_ratio, reply_count, reply_ratio)) %>% 
  arrange(desc(enga_ratio)) %>% 
  head(10)

ttexts <- read_rds("./data/corpii/EU_corpus_cleaned.RDS") %>% 
  select(id, text) %>% 
  filter(id %in% viral$id)

viral <- viral %>%  left_join(ttexts, by = "id")

# Save most viral tweets for presentation

viral2 <- viral %>% 
  mutate(engagements = like_count + retweet_count + quote_count + reply_count) %>% 
  select(c(text, screen_name, day, ifollowers, like_count, retweet_count, quote_count, reply_count, engagements))

viral2$text <- viral2$text %>% # Manual unicode emojis to html - for fucks sake!
  str_replace_all("\U0001F436", "&#x1F436;") %>% 
  str_replace_all("\U0001f6b6\u200D\u2640\uFE0F", "&#x1F6B6;&#x200D;&#x2640;&#xFE0F;") %>% 
  str_replace_all("\U0001F6B2", "&#x1F6B2;") %>%
  str_replace_all("\U0001F447", "&#128071;") %>%
  str_replace_all("\U0001F44D", "&#128077;") %>%
  str_replace_all("\U0001F44F", "&#x1F44F;") %>%
  str_replace_all("\U0001F64F", "&#x1F64F;") %>%
  str_replace_all("\U0001f1ea\U0001f1fa", "&#x1F1EA;&#x1F1FA;") %>%
  str_replace_all("\U0001F6C3", "&#x1F6C3;") %>%
  str_replace_all("\U0001F4B6", "&#x1F4B6;") %>%
  str_replace_all("\U00023F0", "&#x23F0;") %>%
  str_replace_all("\U0001F4AA", "&#x1F4AA;") %>%
  str_replace_all("\U0001F3E2", "&#x1F3E2;") %>%
  str_replace_all("\U0001F40A", "&#x1F40A;") %>%
  str_replace_all("\U0001f992", "&#x1F992;") %>%
  str_replace_all("\U0001F418", "&#x1F418;") %>%
  str_replace_all("\U0001F418", "&#x1F418;") 

# Export
viral.out <- viral2 %>%
  kable(col.names = c("Tweet", "Account", "Date",
                      "Interpolated<br>followers",
                      "Likes", "Retweets", "Quotes", "Replies", "Engagements"), escape =F) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
save_kable(viral.out, "./tables/ViralTweets.html")




# Aggregate engagement ratio over time

pl.enga.time <- # The plot
  ggplot(df.enga %>% filter(group2 == "EU" & day >= as.Date("2011-01-01", "%Y-%m-%d")), 
         aes(x = month, y = enga_ratio/100, group = 1))+
  # geom_point()+
  stat_summary(geom = "line", fun = mean, color = "#003399")+
  # stat_smooth(color = "#003399")+
  # geom_rug(sides = "b", alpha = .2)+
  # scale_y_continuous(breaks = seq(0,3.5,0.5))+
  # coord_cartesian(ylim = c(0, 3.7))+ 
  scale_x_discrete(breaks = t.breaks, labels = t.labels) +
  scale_y_continuous(labels = scales::label_percent(accuracy = 0.01))+
  labs(title = "Average share of followers engaging with supranational tweets",
       subtitle = "Sum of likes, retweets, quotes, and replies divided by follower count at time of tweet",
       x= "", y = "")+
  theme(axis.text.x = element_text(angle = 90, vjust = .5))

ggsave("./plots/UserEngagement/UserEngagementOverTime.png", plot = pl.enga.time, width = 20, height = 12, units = "cm")



# User engagements - cross section ####


# Cross-sample plots
pl.like_ratio <-
  ggplot(df.enga, aes(x = like_ratio/100, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("#FFCC00", "darkred", "#003399"))+
  scale_x_continuous(labels = scales::label_percent(accuracy = 0.01))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Average number of likes\n as share of followers at time of tweet",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))

pl.retweet_ratio <-
  ggplot(df.enga, aes(x = retweet_ratio/100, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("#FFCC00", "darkred", "#003399"))+
  scale_x_continuous(labels = scales::label_percent(accuracy = 0.01))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Average number of retweets\n as share of followers at time of tweet",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))

pl.quote_ratio <-
  ggplot(df.enga, aes(x = quote_ratio/100, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("#FFCC00", "darkred", "#003399"))+
  scale_x_continuous(labels = scales::label_percent(accuracy = 0.01))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Average number of quotes\n as share of followers at time of tweet",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))

pl.reply_ratio <-
  ggplot(df.enga, aes(x = reply_ratio/100, y = group1, color = group2)) +
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", size = .7) + 
  scale_color_manual(values = c("#FFCC00", "darkred", "#003399"))+
  scale_x_continuous(labels = scales::label_percent(accuracy = 0.01))+
  facet_wrap(.~ reorder(group2, desc(group2)), scales = "free_y", ncol = 1, strip.position = "right")+
  labs(title = "Average number of replies\n as share of followers at time of tweet",
       x= "",
       y= "")+
  theme(plot.title = element_text(hjust = .5, face = "bold"))


# Combined plot
pl.engagement_ratio <-
  (pl.like_ratio+pl.retweet_ratio)/
  (pl.quote_ratio+pl.reply_ratio)
ggsave("./plots/UserEngagement/UserEngagementCrossSection.png", plot = pl.engagement_ratio, width = 24, height = 16, units = "cm")


# Clean up
# rm(df.enga)
rm(list=ls(pattern="pl."))
gc()


# Descriptives engagement ratio

mean(df.enga$enga_ratio[df.enga$group2 == "EU"], na.rm = T)
nrow(df.enga %>%  filter(group2 == "EU"))
nrow(df.enga %>%  filter(group2 == "EU" & enga_ratio >= 30))



# Mutlivariate regression - tweet level ####

# Targeted data set
df <- df.enga %>% 
  filter(original) %>% # Only self-authored tweets
  mutate(io = group2 == "IO", # Actor dummies, EU as baseline
         uk = group2 == "UK") %>% 
  mutate(pic = nphotos > 0,
         video = (nvideos+ntube) > 1,
         url = nexturl > 1) %>% 
  mutate(personal = str_detect(group1, fixed("pers. account"))) %>% 
  select(id, screen_name, day, # ID markers for residual analysis
         enga_ratio, # DV: aggregate engagement ratio (DISCUSS!)
         emojicount, pic, video, url, # IVs: Media
         nmentions, nhashtags, # IVs: Responsiveness
         flesch, familiarity, verbal,  # IVs: Language 
         personal, io, uk) %>% # IV: Account types
  mutate_if(is.numeric, list(~na_if(., Inf))) %>% # Replace infinite values with NAs - INSPECT - 8000 cases
  mutate_if(is.numeric, list(~na_if(., -Inf))) %>% # Mostly cases with interpolated follower count == 0 or n_noun == 0
  filter(complete.cases(.)) # Keep only complete cases, mainly drops tweets without english content

# Sample sizes
nrow(df) - (sum(df$io) + sum(df$uk)) # EU tweets
sum(df$io) # IO Tweets
sum(df$uk) # UK Twets


# Store SDs of numeric variables 
# for coefficient interpretation later
sds <- df %>% 
  select(-c(id, screen_name, day)) %>% 
  summarise(across(everything() , sd)) %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  rename(SD = 2,
         variable = 1)


# DV distribution
hist(df$enga_ratio)


# Look at IV distributions
ivs <- df %>% select(4:17)
png(file="./plots/UserEngagement/IvDistributions.png",
    width=1200, height=1200)
corrgram(ivs, # Takes some time
         main = "Distributions of independent variables",
         lower.panel=panel.pts, upper.panel=panel.conf,
         diag.panel=panel.density)
dev.off()



# Crudely linear models ####

# Scale numeric variables
# Want to see standardized coeffcients for a start
dfs <- df %>% 
  mutate_at(c("enga_ratio", 
              "emojicount",
              "nmentions", "nhashtags",
              "flesch", "familiarity", "verbal",
              "pic", "video", "url", 
              "personal", "io", "uk"), # Dummies as well??? To compare effect sizes ...
            scale)
mean(dfs$enga_ratio) # Sanity check
sd(dfs$enga_ratio) # Sanity check


# Regression ####

# Main Model formula
regform <- "enga_ratio ~ uk + io + personal + pic + video + emojicount + url + nmentions + nhashtags + flesch + familiarity + verbal"

# Estimate
fit <- lm(formula = regform, data = dfs)
summary(fit)

# Get coefficients
coef <- coefplot(fit, plot = F)

coefs <- coef %>% 
  mutate(Coefficient = str_remove(Coefficient, "TRUE"), # Clean Dummy names
         Coefficient = str_replace_all(Coefficient, fixed("(Intercept)"), "Intercept")) %>% 
  filter(Coefficient != "Intercept") # Perfectly 0 for full standardization anyway

coefs$name <- NA
coefs$name[coefs$Coefficient == "emojicount"] <- "Number of\nemojis/symbols"
coefs$name[coefs$Coefficient == "video"] <- "Embedded video"
coefs$name[coefs$Coefficient == "pic"] <- "Embedded picture"
coefs$name[coefs$Coefficient == "url"] <- "External link"
coefs$name[coefs$Coefficient == "nmentions"] <- "Number of\n@user mentions"
coefs$name[coefs$Coefficient == "nhashtags"] <- "Number of\n#hashtags"
coefs$name[coefs$Coefficient == "flesch"] <- "Flesch/Kincaid\nreading ease"
coefs$name[coefs$Coefficient == "familiarity"] <- "Familiarity\nof words"
coefs$name[coefs$Coefficient == "verbal"] <- "Verbal style"
coefs$name[coefs$Coefficient == "lsd"] <- "Sentiment\n(Lexicoder)"
coefs$name[coefs$Coefficient == "personal"] <- "Personal\naccount"
coefs$name[coefs$Coefficient == "io"] <- "IO\naccount"
coefs$name[coefs$Coefficient == "uk"] <- "UK\naccount"

coefs$name2 <- factor(coefs$name, 
                      levels = c("Flesch/Kincaid\nreading ease", "Familiarity\nof words", "Verbal style", 
                                 "Embedded picture", "Number of\nemojis/symbols", "Embedded video", "External link",
                                 "Number of\n@user mentions", "Number of\n#hashtags", 
                                 "Personal\naccount", "UK\naccount", "IO\naccount"))

coefs$cat <- NA
coefs$cat[coefs$Coefficient %in% c("flesch", "familiarity", "verbal")] <- "Text"
coefs$cat[coefs$Coefficient %in% c("pic", "emojicount", "video", "url")] <- "Media"
coefs$cat[coefs$Coefficient %in% c("nmentions", "nhashtags")] <- "Discourse"
coefs$cat[coefs$Coefficient %in% c("personal", "uk", "io")] <- "Account"
coefs$cat <- factor(coefs$cat, 
                      levels = c("Text", "Media", "Discourse", "Account"))




# Plot results

theme_set(theme_light())

ggplot(coefs, aes(y = name2))+
  geom_vline(xintercept = 0, linetype = "dashed")+
  geom_linerange(aes(xmin = LowOuter, xmax = HighOuter), size = .5, position = position_dodge(width = .7), color = "#003399") +
  geom_linerange(aes(xmin = LowInner, xmax = HighInner), size = 1, position = position_dodge(width = .7), color = "#003399") +
  geom_point(aes(x = Value), position = position_dodge(width = .7), color = "#003399")+
  facet_wrap(.~cat, scales = "free_y", ncol = 1,
             strip.position = "right")+
  scale_y_discrete(limits=rev)+
  labs(title = "Linear regression models of overall user engagement ratio",
       subtitle = "DV: Sum of likes, retweets, quotes, and replies as share of account followers at tweet time",
       x = "\nStandardized coefficient",
       y = "Tweet\ncharacteristics\n",
       caption = paste("Based on", nrow(dfs), "tweets of executive political institutions and actors from the EU, the UK, and IOs"))+
  theme(legend.position='bottom', 
        axis.text = element_text(color = "black"),
        plot.title = element_text(size=14, face = "bold"),
        panel.grid.minor = element_line(),
        panel.grid.major.y = element_blank(),
        axis.text.x = element_text(angle = 0),
        axis.text.y = element_text(face = "bold"))

ggsave("./plots/UserEngagement/OLS_UserEngagement.png", width = 20, height = 15, units = "cm")


# Substantial effect sizes

sds$SD[sds$variable == "enga_ratio"]

# Change of 30 Point Flesh reading ease score 
delta <- 30/(sds$SD[sds$variable == "flesch"])
effect <- (delta * coef$Value[coef$Coefficient == "flesch"])
substantial <- effect/sds$SD[sds$variable == "enga_ratio"] # In units of DV
substantial
mean(df$enga_ratio)

# One picture
delta <- 1/(sds$SD[sds$variable == "pic"])
effect <- (delta * coef$Value[coef$Coefficient == "pic"])
substantial <- effect/sds$SD[sds$variable == "enga_ratio"] # In units of DV
substantial

# One additional emoji
delta <- 1/(sds$SD[sds$variable == "emojicount"])
effect <- (delta * coef$Value[coef$Coefficient == "emojicount"])
substantial <- effect/sds$SD[sds$variable == "enga_ratio"] # In units of DV
substantial


# Ext url
delta <- 1/(sds$SD[sds$variable == "url"])
effect <- (delta * coef$Value[coef$Coefficient == "url"])
substantial <- effect/sds$SD[sds$variable == "enga_ratio"] # In units of DV
substantial


# Mentions
sum(df$nmentions > 0)
delta <- 1/(sds$SD[sds$variable == "nmentions"])
effect <- (delta * coef$Value[coef$Coefficient == "nmentions"])
substantial <- effect/sds$SD[sds$variable == "enga_ratio"] # In units of DV
substantial

# Hashtags
delta <- 1/(sds$SD[sds$variable == "nhashtags"])
effect <- (delta * coef$Value[coef$Coefficient == "nhashtags"])
substantial <- effect/sds$SD[sds$variable == "enga_ratio"] # In units of DV
substantial

# Personal account
delta <- (sds$SD[sds$variable == "personal"])/1
effect <- (delta * coef$Value[coef$Coefficient == "personal"])
substantial <- effect/sds$SD[sds$variable == "enga_ratio"] # In units of DV
substantial



# OLD #####





# Targeted data set
df <- tweets %>% 
  filter(original) %>% # Only self-authored tweets
  select(id, screen_name, day, # ID markers for residual analysis
         like_ratio, retweet_ratio, quote_ratio, reply_ratio, # DVs: engagement rates
         emojicount, pic, video, url, # IVs: Media
         nmentions, nhashtags, # IVs: Responsiveness
         flesch, familiarity, verbal, # IVs: Language 
         personal) %>% # IV: Personal account
  mutate_if(is.numeric, list(~na_if(., Inf))) %>% # Replace infinite values with NAs - INSPECT - 8000 cases
  mutate_if(is.numeric, list(~na_if(., -Inf))) %>% # Mostly cases with interpolated follower count == 0 or n_noun == 0
  filter(complete.cases(.)) # Keep only complete cases, mainly drops tweets without english content




# Why the heck are hastag and mention counts perfectly correlated???
# In analytic data set creation i lokks godd (line 28 ff)


# # Look at DV distributions
# dvs <- df %>% select(c(like_ratio, retweet_ratio, quote_ratio, reply_ratio))
# cors <- round(cor(dvs), 1) # Correlation matrix
# 
# png(file="./plots/UserEngagement/EngagementRatioDistributions.png",
#     width=600, height=600)
# corrgram(dvs, # Takes some time
#          main = "Distributions of engagement indicators",
#          lower.panel=panel.pts, upper.panel=panel.conf,
#          diag.panel=panel.density)
# dev.off()
# 
# # Ugly ! Extremely skewed and overdispersed - seems to call for Poisson or negative binomial
# 
# apply(dvs, 2, mean) # Means
# apply(dvs, 2, var) # Variances
# 
# # Overdispersion (against normal), not dramatic at first sight, but still skew and possible zero-inflation



# Crudely linear models ####

# Scale numeric variables
# Want to see standardized coeffcients for a start
dfs <- df %>% 
  mutate_at(c("like_ratio", "retweet_ratio", "quote_ratio", "reply_ratio",
              "emojicount",
              "nmentions", "nhashtags",
              "flesch", "familiarity", "verbal", "lsd",
              "pic", "video", "url", "personal"), # Dummies as well??? To compare effect sizes ...
            scale)
mean(dfs$like_ratio) # Sanity check
sd(dfs$like_ratio) # Sanity check



# Main Model formula
regform <- "personal + pic + video + emojicount + url + nmentions + nhashtags + flesch + familiarity + verbal + lsd"


# Regressions 

likeform <- paste0("like_ratio ~ ", regform)
like.fit <- lm(formula = likeform, data = dfs)
like.coef <- coefplot(like.fit, plot = F) %>% 
  mutate(Model = "Like ratio")

retweetform <- paste0("retweet_ratio ~ ", regform)
retweet.fit <- lm(formula = retweetform, data = dfs)
retweet.coef <- coefplot(retweet.fit, plot = F) %>% 
  mutate(Model = "Retweet ratio")

quoteform <- paste0("quote_ratio ~ ", regform)
quote.fit <- lm(formula = quoteform, data = dfs)
quote.coef <- coefplot(quote.fit, plot = F) %>% 
  mutate(Model = "Quote ratio")

replyform <- paste0("reply_ratio ~ ", regform)
reply.fit <- lm(formula = replyform, data = dfs)
reply.coef <- coefplot(reply.fit, plot = F) %>% 
  mutate(Model = "Reply ratio")

# Combine and clean coefficient info

coefs <- rbind(like.coef,
               retweet.coef,
               quote.coef,
               reply.coef) %>% 
  mutate(Coefficient = str_remove(Coefficient, "TRUE"), # Clean Dummy names
         Coefficient = str_replace_all(Coefficient, fixed("(Intercept)"), "Intercept")) %>% 
  filter(Coefficient != "Intercept") # Perfectly 0 for full standardization anyway

coefs$Model <- factor(coefs$Model, levels = c("Like ratio", "Retweet ratio", "Reply ratio", "Quote ratio"))

coefs$name <- NA
coefs$name[coefs$Coefficient == "emojicount"] <- "Number of\nemojis/symbols"
coefs$name[coefs$Coefficient == "video"] <- "Embedded video"
coefs$name[coefs$Coefficient == "pic"] <- "Embedded picture"
coefs$name[coefs$Coefficient == "url"] <- "External link"
coefs$name[coefs$Coefficient == "nmentions"] <- "Number of\n@user mentions"
coefs$name[coefs$Coefficient == "nhashtags"] <- "Number of\n#hashtags"
coefs$name[coefs$Coefficient == "flesch"] <- "Flesch/Kincaid\nreading ease"
coefs$name[coefs$Coefficient == "familiarity"] <- "Familiarity\nof words"
coefs$name[coefs$Coefficient == "verbal"] <- "Verbal style"
coefs$name[coefs$Coefficient == "lsd"] <- "Sentiment\n(Lexicoder)"
coefs$name[coefs$Coefficient == "personal"] <- "Personal\naccount"

coefs$name2 <- factor(coefs$name, 
                      levels = c("Number of\n@user mentions", "Number of\n#hashtags", "Number of\nemojis/symbols",
                                 "Embedded picture", "Embedded video", "External link",
                                 "Flesch/Kincaid\nreading ease", "Familiarity\nof words", "Verbal style", "Sentiment\n(Lexicoder)",
                                 "Personal\naccount"))

# Plot results

theme_set(theme_light())

ggplot(coefs, aes(y = name2, color = Model))+
  geom_vline(xintercept = 0, linetype = "dashed")+
  geom_linerange(aes(xmin = LowOuter, xmax = HighOuter), size = .5, position = position_dodge(width = .7)) +
  geom_linerange(aes(xmin = LowInner, xmax = HighInner), size = 1, position = position_dodge(width = .7)) +
  geom_point(aes(x = Value), position = position_dodge(width = .7))+
  scale_colour_manual(values = c("red", "green", "blue", "gray30"))+
  geom_hline(yintercept = c(seq(1.5, 10.5, 1)), color = "gray70")+
  labs(title = "Linear regression models of user engagement",
       subtitle = paste("Based on", nrow(dfs), "tweets of\npersonal and institutional accounts of supranational EU actors"),
       x = "\nStandardized effect",
       y = "Tweet\ncharacteristics\n",
       color = "Engagement indicator: ")+
  theme(legend.position='bottom', 
        axis.text = element_text(color = "black"),
        plot.title = element_text(size=14, face = "bold"),
        panel.grid.minor = element_line(),
        panel.grid.major.y = element_blank(),
        axis.text.x = element_text(angle = 0),
        axis.text.y = element_text(face = "bold"))

ggsave("./plots/UserEngagement/OLS_UserEngagement.png", width = 20, height = 15, units = "cm")

  

