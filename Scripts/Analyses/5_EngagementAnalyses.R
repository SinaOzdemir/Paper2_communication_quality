########################################################
# Project:    EU Tweet
# Task:       Analyse user engagement 
# Author:     Christian Rauh (24.06.2021)
########################################################


# Packages #####
library(tidyverse) # 1.3.0
library(patchwork) # 1.1.1
library(scales) # 1.1.1
library(corrgram) 
library(coefplot)
library(margins)
library(kableExtra) # 1.3.1
library(utf8)




# Prepare data ####

# As generated by 3_AnalyticDataSet.R and preceeding steps
# w/out random tweetes
tweets <- read_rds("./data/AnalyticData_AllSamples.RDS") %>% 
  filter(!str_detect(tweetsample, "Random "))

# Filter some accounts
tweets <- tweets %>% 
  filter(screen_name != "HMRCcustomers") %>%  # Customer support account
  filter(screen_name != "DVLAgovuk") %>%      # Online service account of the Driver&Vehicle licensing agency
  filter(screen_name != "nsandihelp")         # A help desk (what is this org anyway?)


# Add personal institutional distinction for the IO sample
# Coding by CR and KBH consistent
iopersonal <- read.csv2("./analysis_data/IO_account_coding_CR.csv") %>% 
  filter(personal == 1) 
iopersonal <- iopersonal[,1] # Screen names to atomic vector
tweets$tweetsample[tweets$screen_name %in% iopersonal] <- "IO (pers. account)"
tweets$tweetsample[tweets$tweetsample == "IO"] <- "IO (inst. account)"
rm(iopersonal)

# Clean group variables (for plotting)
tweets$group1 <- tweets$tweetsample %>% 
  str_replace(" ", "\n") %>% ## Add line breaks
  factor(levels = c("EU\n(inst. account)", # Order as factor
                    "EU\n(pers. account)",
                    "UK\n(inst. account)",
                    "UK\n(pers. account)",
                    "IO\n(inst. account)",
                    "IO\n(pers. account)",
                    "Random\nTweets")) %>% 
  fct_rev() # Reverse, so that EU always comes out on top (for horizontal plots, reverse in ggplot call)

tweets$group2 <- tweets$tweetsample %>% 
  str_remove(" .*$") %>% # Remove pers/inst distinction (for color coding later)
  factor(levels = c("EU", # Order as factor
                    "UK",
                    "IO",
                    "Random")) %>% 
  fct_rev() # Reverse, so that EU alsways comes out on top

# Mark group of benchmark samples separately
tweets$benchmark <- !str_detect(tweets$tweetsample, "EU ")

# Retain copy of screen_names / sample assocs
# for easy labelling aggregated data downstream
account.types <- tweets %>% 
  select(screen_name, group1, group2, benchmark) %>% 
  unique()
account.types <- account.types %>% 
  filter(!(screen_name == "BaldwinMatthew_" & group2 == "Random")) # Crazy coincidence!
sum(duplicated(account.types$screen_name))


# Correct some coding nuissances
# Probably correct downstream!
tweets$nexturl[is.na(tweets$nexturl)] <- 0 # there were just none
tweets$nphotos[is.na(tweets$nphotos)] <- 0 # there were just none
tweets$nvideos[is.na(tweets$nvideos)] <- 0 # there were just none
tweets$ntube[is.na(tweets$ntube)] <- 0 # there were just none
tweets$lsd[!tweets$en_av] <- NA # If there was no english text, sentiment score is missing, not 0

# Mark original (self-authored) tweets
# excluding retweets and quotes
tweets$original <- tweets$is_retweet == F & tweets$is_quote == F
sum(tweets$original)

# Filter original tweets
# All engagement analysis only on self-authored messages
tweets <- tweets %>% filter(original)

# Time markers
tweets$month <- str_extract(as.character(tweets$day), "[0-9]{4}-[0-9]{2}")



# Add follower  ####

fcounts <- rbind(read_rds("./analysis_data/FollowerCountsInterpolated_EU.RDS"),
                 read_rds("./analysis_data/FollowerCountsInterpolated_IO.RDS"),
                 read_rds("./analysis_data/FollowerCountsInterpolated_UK.RDS")) %>% 
  select(-follower_count) %>% 
  rename(day = date,
         ifollowers = follower_count_interpolated)

tweets <- tweets %>% left_join(fcounts, by = c("screen_name", "day"))
sum(is.na(tweets$ifollowers))



# Normalize user engagement allong follower count ####

tweets$ifollowers[tweets$ifollowers == 0] <- 1 # Prevent infinite reatios, we interpolated from 0

tweets$like_ratio <- (tweets$like_count/tweets$ifollowers)*100
tweets$retweet_ratio <- (tweets$retweet_count/tweets$ifollowers)*100
tweets$quote_ratio <- (tweets$quote_count/tweets$ifollowers)*100
tweets$reply_ratio <- (tweets$reply_count/tweets$ifollowers)*100

tweets <- tweets %>% 
  mutate(enga_ratio = like_ratio + retweet_ratio + quote_ratio + reply_ratio) # Overall engagement rate


# Overarching ggplot params ####
theme_set(theme_light() +
            theme(legend.position = "none",
                  axis.text = element_text(color = "black"),
                  plot.title = element_text(size=10, face = "bold"),
                  plot.subtitle = element_text(size=10),
                  panel.grid.minor = element_blank()))



# EU follower counts ####

# Monthly breaks/labels
t.breaks <- tweets[tweets$group2 == "EU", "month"][,1] %>% # Labelling breaks
  unique() %>% 
  arrange(month) 
t.breaks <- t.breaks[[1]] 
t.breaks <- t.breaks[str_detect(t.breaks, "-01")] # Januaries
t.labels <- t.breaks %>% str_extract("[0-9]{4}") # Years for labelling

# Eu follower counts 
eufollowers <- tweets %>% 
  filter(group2 == "EU") %>% 
  group_by(month) %>% 
  summarise(maxf = max(ifollowers, na.rm = T),
            meanf = round(mean(ifollowers, na.rm = T),0),
            minf = min(ifollowers, na.rm = T),
            medianf = median(ifollowers, na.rm = T))

# Plot
pl.followers <- 
  ggplot(eufollowers, aes(x=month, group = 1)) + 
  geom_line(aes(y=maxf), color = "#003399")+
  geom_line(aes(y=medianf), color = "#003399")+
  geom_line(aes(y=meanf), color = "#003399")+
  annotate(geom = "label", x = 140, y = eufollowers$maxf[140], label = "Max", color = "#003399")+
  annotate(geom = "label", x = 140, y = eufollowers$meanf[140], label = "Mean", color = "#003399")+
  annotate(geom = "label", x = 140, y = eufollowers$medianf[140], label = "Median", color = "#003399")+
  labs(title = "Number of followers of supranational EU accounts",
       x= "", y = "")+
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_y_continuous(breaks = seq(0, 1500000, 100000),label=comma)

ggsave("./plots/UserEngagement/EUfollowersTime.png", plot = pl.followers, width = 24, height = 10, units = "cm")
  

# Followers by account (max)

accountfollowers <- tweets %>% 
  filter(group2 == "EU") %>% 
  group_by(screen_name) %>% 
  summarise(maxf = max(ifollowers, na.rm = T),
            personal = mean(str_detect(group1, "pers. account"))) %>% 
  arrange(desc(maxf))

head(accountfollowers, 10)
tail(accountfollowers, 10)

# Personal vs institutional accounts
t.test(accountfollowers$maxf[accountfollowers$personal == 1], accountfollowers$maxf[accountfollowers$personal == 0])


# Snapshot availability
eusnaps <- read_rds("./analysis_data/EU-snapshots.RDS")
eusnaps[eusnaps$snapshots == max(eusnaps$snapshots), ]
eusnaps[eusnaps$snapshots == min(eusnaps$snapshots[eusnaps$snapshots != 0]), ]
sum(eusnaps$snapshots == 0)



# Descriptive analysis of user engagement ####

# The most viral supranational tweets

hist(tweets$enga_ratio[tweets$group2 == "EU"])

viral <- tweets %>% 
  filter(group2 == "EU") %>% 
  select(c(id, day, screen_name, ifollowers, enga_ratio, 
           like_count, like_ratio, retweet_count, retweet_ratio,
           quote_count, quote_ratio, reply_count, reply_ratio)) %>% 
  arrange(desc(enga_ratio)) %>% 
  head(10)

ttexts <- read_rds("./data/corpii/EU_corpus_cleaned.RDS") %>% 
  select(id, text) %>% 
  filter(id %in% viral$id)

viral <- viral %>%  left_join(ttexts, by = "id")

# Hmpf ... 'hello world' tweets - entirely driven by underestimating the follower count
# We need to filter - only when and after snapshots are available

# Filter sample along snapshot dates

# Snapshot info
snapav <- rbind(read_rds("./analysis_data/FollowerCountsInterpolated_EU.RDS"), # Follower counts
                read_rds("./analysis_data/FollowerCountsInterpolated_IO.RDS"),
                read_rds("./analysis_data/FollowerCountsInterpolated_UK.RDS")) %>%
  filter(follower_count != 0 & # Drop obs without follower count measurement
           !is.na(follower_count)) %>% 
  select(-follower_count_interpolated) %>% 
  group_by(screen_name) %>% 
  summarise(earliest = min(date), # Earliest snapshot by account
            snaps = n()) %>% # Number of snaps by account
  filter(snaps > 1) # At least two snapshots need to be available
  
# Filter users
tweets2 <- tweets %>% filter(screen_name %in% snapav$screen_name)

# Filter tweets by earliest snapshot
df.enga <- data.frame()

for (account in unique(tweets2$screen_name)) {
  
  # Progres
  print(account)
  
  # Select and filter tweets
  dat <- tweets2 %>% 
    filter(screen_name == account) %>% # All Tweets from that account
    filter(day >= snapav$earliest[snapav$screen_name == account]) # Only from ealiest snapshot date
  
  # Append to target
  df.enga <- rbind(df.enga, dat)
}

rm(dat)
gc()


# The most viral supranational tweets in that reduced sample

hist(df.enga$enga_ratio[df.enga$group2 == "EU"])

viral <- df.enga %>% 
  filter(group2 == "EU") %>% 
  select(c(id, day, screen_name, ifollowers, enga_ratio, 
           like_count, like_ratio, retweet_count, retweet_ratio,
           quote_count, quote_ratio, reply_count, reply_ratio)) %>% 
  arrange(desc(enga_ratio)) %>% 
  head(10)

ttexts <- read_rds("./data/corpii/EU_corpus_cleaned.RDS") %>% 
  select(id, text) %>% 
  filter(id %in% viral$id)

viral <- viral %>%  left_join(ttexts, by = "id")

# Save most viral tweets for presentation

viral2 <- viral %>% 
  mutate(engagements = like_count + retweet_count + quote_count + reply_count) %>% 
  select(c(text, screen_name, ifollowers, like_count, retweet_count, quote_count, reply_count, engagements))

viral2$text <- viral2$text %>% # Manual unicode emojis to html - for fucks sake!
  str_replace_all("\U0001F436", "&#x1F436;") %>% 
  str_replace_all("\U0001f6b6\u200D\u2640\uFE0F", "&#x1F6B6;&#x200D;&#x2640;&#xFE0F;") %>% 
  str_replace_all("\U0001F6B2", "&#x1F6B2;") %>%
  str_replace_all("\U0001F447", "&#128071;") %>%
  str_replace_all("\U0001F44D", "&#128077;") %>%
  str_replace_all("\U0001F44F", "&#x1F44F;") %>%
  str_replace_all("\U0001F64F", "&#x1F64F;") %>%
  str_replace_all("\U0001f1ea\U0001f1fa", "&#x1F1EA;&#x1F1FA;") %>%
  str_replace_all("\U0001F6C3", "&#x1F6C3;") %>%
  str_replace_all("\U0001F4B6", "&#x1F4B6;") %>%
  str_replace_all("\U00023F0", "&#x23F0;") %>%
  str_replace_all("\U0001F4AA", "&#x1F4AA;") %>%
  str_replace_all("\U0001F3E2", "&#x1F3E2;") %>%
  str_replace_all("\U0001F40A", "&#x1F40A;") %>%
  str_replace_all("\U0001f992", "&#x1F992;") %>%
  str_replace_all("\U0001F418", "&#x1F418;") %>%
  str_replace_all("\U0001F418", "&#x1F418;") 

# Export
viral.out <- viral2 %>%
  kable(col.names = c("Tweet", "Account",
                      "Interpolated<br>followers",
                      "Likes", "Retweets", "Quotes", "Replies", "Engagements"), escape =F) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
save_kable(viral.out, "./tables/ViralTweets.html")




# Aggregate engament ratio over time

pl.enga.time <- # The plot
  ggplot(df.enga %>% filter(group2 == "EU" & day >= as.Date("2011-01-01", "%Y-%m-%d")), aes(x = month, y = enga_ratio, group = 1))+
  # geom_point()+
  stat_summary(geom = "line", fun = mean, "#003399")+
  # stat_smooth(color = "#003399")+
  # geom_rug(sides = "b", alpha = .2)+
  # scale_y_continuous(breaks = seq(0,3.5,0.5))+
  # coord_cartesian(ylim = c(0, 3.7))+ 
  scale_x_discrete(breaks = t.breaks, labels = t.labels) +
  labs(title = "Average number of followers engaging at least once with supranational tweets",
       subtitle = "Average sum of likes, retweets, quotes, and replies divided by follower count at time of the tweet",
       x= "", y = "")+
  theme(axis.text.x = element_text(angle = 90, vjust = .5))

ggsave("./plots/UserEngagement/UserEngagementOverTime.png", plot = pl.enga.time, width = 20, height = 12, units = "cm")



# HERE



# Likes
pl.like_count <-
  ggplot(df.enga, aes(x = month, y = like_count, color = personal, group = personal)) +
  stat_summary(geom = "line", fun = "mean", ) +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of likes\nper supranational tweet and month",
       x = "",
       y = "",
       color = "Author account type:")+
  theme(legend.position = c(0.25,.85),
        legend.background = element_blank(),
        legend.text = element_text(size= 10),
        legend.title = element_text(size= 10))

pl.like_ratio <-
  ggplot(df.enga, aes(x = month, y = like_ratio, color = personal, group = personal)) +
  stat_smooth() +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_y_continuous(labels = scales::label_percent(accuracy = 0.01))+
  coord_cartesian(ylim = c(0,NA))+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of likes\nper supranational tweet\nas share of account followers",
       x = "",
       y = "",
       color = "Author account type:")+
  theme(legend.position = c(0.25,.85),
        legend.background = element_blank(),
        legend.text = element_text(size= 10),
        legend.title = element_text(size= 10))


# Retweets
pl.retweet_count <-
  ggplot(df.enga, aes(x = month, y = retweet_count, color = personal, group = personal)) +
  stat_summary(geom = "line", fun = "mean", ) +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of retweets\nper supranational tweet and month",
       x = "",
       y = "")

pl.retweet_ratio <-
  ggplot(df.enga, aes(x = month, y = retweet_ratio, color = personal, group = personal)) +
  stat_smooth() +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_y_continuous(labels = scales::label_percent(accuracy = 0.01))+
  coord_cartesian(ylim = c(0,NA))+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of retweets\nper supranational tweet\nas share of account followers",
       x = "",
       y = "")


# Quotes
pl.quote_count <-
  ggplot(df.enga, aes(x = month, y = quote_count, color = personal, group = personal)) +
  stat_summary(geom = "line", fun = "mean", ) +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of quotes\nper supranational tweet and month",
       x = "",
       y = "")

pl.quote_ratio <-
  ggplot(df.enga, aes(x = month, y = quote_ratio, color = personal, group = personal)) +
  stat_smooth() +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_y_continuous(labels = scales::label_percent(accuracy = 0.01))+
  coord_cartesian(ylim = c(0,NA))+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of quotes\nper supranational tweet\nas share of account followers",
       x = "",
       y = "")


# Replies
pl.reply_count <-
  ggplot(df.enga, aes(x = month, y = reply_count, color = personal, group = personal)) +
  stat_summary(geom = "line", fun = "mean", ) +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of replies\nper supranational tweet and month",
       x = "",
       y = "")

pl.reply_ratio <-
  ggplot(df.enga, aes(x = month, y = reply_ratio, color = personal, group = personal)) +
  stat_smooth() +
  scale_x_discrete(breaks = t.breaks, labels = t.labels)+
  scale_y_continuous(labels = scales::label_percent(accuracy = 0.01))+
  coord_cartesian(ylim = c(0,NA))+
  scale_colour_manual(values = c("#003399", "#1da1f2"), labels = c("institutional", "personal")) +
  labs(title = "Average number of replies\nper supranational tweet\nas share of account followers",
       x = "",
       y = "")

# Combined plots
pl.engagement_count <-
  (pl.like_count+pl.retweet_count)/
  (pl.quote_count+pl.reply_count)
ggsave("./plots/UserEngagement/UserEngagementOverTimeAbsolute.png", plot = pl.engagement_count, width = 20, height = 20, units = "cm")

pl.engagement_ratio <-
  (pl.like_ratio+pl.retweet_ratio)/
  (pl.quote_ratio+pl.reply_ratio)
ggsave("./plots/UserEngagement/UserEngagementOverTimeRatio.png", plot = pl.engagement_ratio, width = 20, height = 20, units = "cm")

# Clean up
rm(df.enga)
rm(list=ls(pattern="pl."))
gc()




# Mutlivariate regression - tweet level ####

# Targeted data set
df <- tweets %>% 
  filter(original) %>% # Only self-authored tweets
  select(id, screen_name, day, # ID markers for residual analysis
         like_ratio, retweet_ratio, quote_ratio, reply_ratio, # DVs: engagement rates
         emojicount, pic, video, url, # IVs: Media
         nmentions, nhashtags, # IVs: Responsiveness
         flesch, familiarity, verbal, lsd, # IVs: Language 
         personal) %>% # IV: Personal account
  mutate_if(is.numeric, list(~na_if(., Inf))) %>% # Replace infinite values with NAs - INSPECT - 8000 cases
  mutate_if(is.numeric, list(~na_if(., -Inf))) %>% # Mostly cases with interpolated follower count == 0 or n_noun == 0
  filter(complete.cases(.)) # Keep only complete cases, mainly drops tweets without english content


# Outliers
# 'Viral' tweets that created more engagement than followers
like.outliers <- df %>%  filter(like_ratio > 1)
retweet.outliers <- df %>%  filter(retweet_ratio > 1)
quote.outliers <- df %>%  filter(quote_ratio > 1)
reply.outliers <- df %>%  filter(reply_ratio > 1)

outlier.ids <- c(like.outliers$id,
                     retweet.outliers$id,
                     quote.outliers$id,
                     reply.outliers$id) %>% 
  as.data.frame() %>% 
  rename(id = 1) %>% 
  group_by(id) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

# Inspect and save
# raw <- read_rds("./data/corpii/EU_corpus_cleaned.RDS") %>% 
#   filter(id %in% outlier.ids$id)
# write_rds(raw, "./analysis_data/UnusualEngagementCases.RDS")
# rm(raw)


# Drop outliers from regression data
# NB!
df <- df %>% filter(!(id %in% outlier.ids$id))


# Store SDs of numeric variables 
# for coefficient interpretation later
sds <- df %>% 
  select(c(like_ratio, retweet_ratio, quote_ratio, reply_ratio,
           emojicount,
           nmentions, nhashtags,
           flesch, familiarity, verbal, lsd)) %>% 
  summarise(across(everything() , sd)) %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  rename(SD = 1,
         variable = 2)


# Look at DV distributions
dvs <- df %>% select(c(like_ratio, retweet_ratio, quote_ratio, reply_ratio))
cors <- round(cor(dvs), 1) # Correlation matrix

png(file="./plots/UserEngagement/EngagementRatioDistributions.png",
    width=600, height=600)
corrgram(dvs, # Takes some time
         main = "Distributions of engagement indicators",
         lower.panel=panel.pts, upper.panel=panel.conf,
         diag.panel=panel.density)
dev.off()

# Ugly ! Extremely skewed and overdispersed - seems to call for Poisson or negative binomial

apply(dvs, 2, mean) # Means
apply(dvs, 2, var) # Variances

# Overdispersion (against normal), not dramatic at first sight, but still skew and possible zero-inflation


# Look at IV distributions
ivs <- df %>% select(8:18)
png(file="./plots/UserEngagement/IvDistributions.png",
    width=1200, height=1200)
corrgram(ivs, # Takes some time
         main = "Distributions of independent variables",
         lower.panel=panel.pts, upper.panel=panel.conf,
         diag.panel=panel.density)
dev.off()

# Why the heck are hastag and mention counts perfectly correlated???
# In analytic data set creation i lokks godd (line 28 ff)



# Crudely linear models ####

# Scale numeric variables
# Want to see standardized coeffcients for a start
dfs <- df %>% 
  mutate_at(c("like_ratio", "retweet_ratio", "quote_ratio", "reply_ratio",
              "emojicount",
              "nmentions", "nhashtags",
              "flesch", "familiarity", "verbal", "lsd",
              "pic", "video", "url", "personal"), # Dummies as well??? To compare effect sizes ...
            scale)
mean(dfs$like_ratio) # Sanity check
sd(dfs$like_ratio) # Sanity check



# Main Model formula
regform <- "personal + pic + video + emojicount + url + nmentions + nhashtags + flesch + familiarity + verbal + lsd"


# Regressions 

likeform <- paste0("like_ratio ~ ", regform)
like.fit <- lm(formula = likeform, data = dfs)
like.coef <- coefplot(like.fit, plot = F) %>% 
  mutate(Model = "Like ratio")

retweetform <- paste0("retweet_ratio ~ ", regform)
retweet.fit <- lm(formula = retweetform, data = dfs)
retweet.coef <- coefplot(retweet.fit, plot = F) %>% 
  mutate(Model = "Retweet ratio")

quoteform <- paste0("quote_ratio ~ ", regform)
quote.fit <- lm(formula = quoteform, data = dfs)
quote.coef <- coefplot(quote.fit, plot = F) %>% 
  mutate(Model = "Quote ratio")

replyform <- paste0("reply_ratio ~ ", regform)
reply.fit <- lm(formula = replyform, data = dfs)
reply.coef <- coefplot(reply.fit, plot = F) %>% 
  mutate(Model = "Reply ratio")

# Combine and clean coefficient info

coefs <- rbind(like.coef,
               retweet.coef,
               quote.coef,
               reply.coef) %>% 
  mutate(Coefficient = str_remove(Coefficient, "TRUE"), # Clean Dummy names
         Coefficient = str_replace_all(Coefficient, fixed("(Intercept)"), "Intercept")) %>% 
  filter(Coefficient != "Intercept") # Perfectly 0 for full standardization anyway

coefs$Model <- factor(coefs$Model, levels = c("Like ratio", "Retweet ratio", "Reply ratio", "Quote ratio"))

coefs$name <- NA
coefs$name[coefs$Coefficient == "emojicount"] <- "Number of\nemojis/symbols"
coefs$name[coefs$Coefficient == "video"] <- "Embedded video"
coefs$name[coefs$Coefficient == "pic"] <- "Embedded picture"
coefs$name[coefs$Coefficient == "url"] <- "External link"
coefs$name[coefs$Coefficient == "nmentions"] <- "Number of\n@user mentions"
coefs$name[coefs$Coefficient == "nhashtags"] <- "Number of\n#hashtags"
coefs$name[coefs$Coefficient == "flesch"] <- "Flesch/Kincaid\nreading ease"
coefs$name[coefs$Coefficient == "familiarity"] <- "Familiarity\nof words"
coefs$name[coefs$Coefficient == "verbal"] <- "Verbal style"
coefs$name[coefs$Coefficient == "lsd"] <- "Sentiment\n(Lexicoder)"
coefs$name[coefs$Coefficient == "personal"] <- "Personal\naccount"

coefs$name2 <- factor(coefs$name, 
                      levels = c("Number of\n@user mentions", "Number of\n#hashtags", "Number of\nemojis/symbols",
                                 "Embedded picture", "Embedded video", "External link",
                                 "Flesch/Kincaid\nreading ease", "Familiarity\nof words", "Verbal style", "Sentiment\n(Lexicoder)",
                                 "Personal\naccount"))

# Plot results

theme_set(theme_light())

ggplot(coefs, aes(y = name2, color = Model))+
  geom_vline(xintercept = 0, linetype = "dashed")+
  geom_linerange(aes(xmin = LowOuter, xmax = HighOuter), size = .5, position = position_dodge(width = .7)) +
  geom_linerange(aes(xmin = LowInner, xmax = HighInner), size = 1, position = position_dodge(width = .7)) +
  geom_point(aes(x = Value), position = position_dodge(width = .7))+
  scale_colour_manual(values = c("red", "green", "blue", "gray30"))+
  geom_hline(yintercept = c(seq(1.5, 10.5, 1)), color = "gray70")+
  labs(title = "Linear regression models of user engagement",
       subtitle = paste("Based on", nrow(dfs), "tweets of\npersonal and institutional accounts of supranational EU actors"),
       x = "\nStandardized effect",
       y = "Tweet\ncharacteristics\n",
       color = "Engagement indicator: ")+
  theme(legend.position='bottom', 
        axis.text = element_text(color = "black"),
        plot.title = element_text(size=14, face = "bold"),
        panel.grid.minor = element_line(),
        panel.grid.major.y = element_blank(),
        axis.text.x = element_text(angle = 0),
        axis.text.y = element_text(face = "bold"))

ggsave("./plots/UserEngagement/OLS_UserEngagement.png", width = 20, height = 15, units = "cm")

  

