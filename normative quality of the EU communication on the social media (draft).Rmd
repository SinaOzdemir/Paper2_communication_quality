---
title: "Normative quality of the EU communication on Social Media"
author: "Sina F. Oezdemir"
date: "`r format(Sys.time(), '%d %M %Y')`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packs<-c("quanteda","tidyverse","twokenizer")
lapply(packs,library,character.only = T)
```



## Abstract:

The legitimacy of the EU as a polity is in crisis beyond doubt at this point. Referendums such as the European Constitution referendum in 2005, the infamous Brexit referendum, Danish, and Swedish referendums on joining the eurozone. On the one hand, the unprecedented levels of integration have led to more significant public contestation of the European Unionâ€™s legitimacy as a supranational polity; on the other hand, the EU has become increasingly reliant on public support for legitimacy. While the academic debate has produced a considerable amount of knowledge on the reasons and possible solutions to this crisis based on output, input and throughput legitimacy , there is comparatively limited academic work on the communication dimension of the legitimacy crisis. We know that the EU has problems when it comes to communicating its political value to its citizens. On the one hand, the EU faces a fractured public sphere. Consequently, it has communicate with its citizens through national media channels and national political elite all the while they show limited interest in telling what the EU is about. On the other hand, the EU is not able to lead an effective public communication. 

The social media platforms offer a unique chance to the EU institution for public communication. This paper sets forth to examine how and to what extent the EU social media communication meets the normative demands for communication vis-a-vis legitimacy. Extant literature spells out six criteria for a public communication to supplement institutional legitimacy. These criteria are: 1) *informing the public clearly and comprehensively about political targets and facts*,2) *make political responsibilities visible*,3) *explain the political conflicts in decision making*,4) *inform the public about the decision making procedures*,5) *justify the political decisions*,6) *information exchange between the two communication partners*. 


In this paper, we focus on demand one, two, and six and analyze the public communication of the EU on Twitter with automated content analysis. We operationalize demand one as comprehensibility of communication and measure it using Flesch ease-of-read formula. As for demand two, we operationalize it as the number of tweets where the EU twitter accounts mention *who has done what*. To measure this, we use part-of-speech tagging to identify the number of tweets that contains "personal pronouns + action verb" combination as well as "relevant mention + action verb". Lastly, we conceive demand six as replying to the audience on Twitter (i.e dialogical communication). We measure the levels of dialog between the EU accounts and their audience as the percentage share of reply tweets to followers in the total number of tweets by the Eu accounts.



#### Some notes:

1. I have tweets from 118 verified EU twitter accounts and replies to these tweets, collected between 01.12.2019 and 30.07.2020. The accounts belong the key EU institutions as well as commissioners, agencies and the Commission bureaucrats. We can trim this down as we see fit. I know have access to Twitter academic API V2.0, so there is a possibility to enlarge it. I also collected the user IDs of the followers of these accounts (yes, I have 8 million user IDs).

2. https://github.com/b05102139/twokenizer is for twitter specific POS tagger. Will be very handy for tokenizing and calculating some of the readability indexes.

3. Flesch Reading ease formula:

$RE = 206.835 - (1.015 * ASL) - (85.6* ASW)$

where

RE: Reading ease

ASL: average sentence length (i.e, the number of words divided by the number of sentences)

ASW: average number of syllables per word (i.e number of syllables divided by the number of words)

scores between 100 - 90 means the text is easily understandable by an average 5th grader, 70-60 for 8th & 9th graders, 30 - 0 by collage graduates.

Overall scores can be interpreted as:

100 - 90: Very easy
89-80: Easy
79-70: Fairly easy
69-60: Standard
59-50: Fairly difficult
49-30: Difficult
29-0: Confusing

4. Alternative calculation of ease of read: Dale-Chall formula

https://readabilityformulas.com/new-dale-chall-readability-formula.php

This formula makes use "hard" and "familiar" words. Higher the percentage of "hard" words in a text, harder it is to read. They have up to 3000. This can be expanded by using google books using [this](https://github.com/hackerb9/gwordlist). This is more language specific than Flesch ease-of-read formula because the "hard" words are judged whether they would be easily recognized by a 3rd grader in the US.

```{r familiarwods, eval = F, echo = F}
library(rvest)

wordlistpage<-read_html("https://readabilityformulas.com/articles/dale-chall-readability-word-list.php")

wordlist<-wordlistpage %>% html_nodes(css = "strong , .article_wordlist td") %>% html_text()

wordlista<-wordlist[which(str_length(string = wordlist)>1)]

wordlistb<-data.frame(common_words = str_split(wordlista,pattern = " ") %>% unlist()) 

write.table(x = wordlistb,file = paste(getwd(),"dale-chall_familiar_words_dictionary.txt",sep = "/"),
            sep = ",",fileEncoding = "UTF-8",row.names = F)
```
```{r famwordtable, echo=F,eval = T}
read.table(file =  paste(getwd(),"dale-chall_familiar_words_dictionary.txt",sep = "/"),col.names = "familiar_words")%>% slice_sample(.,n = 10) %>% pander::pander(x = .,style = "rmarkdown", caption = "Dale-Chall extended familiar word list example")

```

5. We can also create an additional criteria of normative quality of communication unique to social media. These can be:

    1) Accommodating the fractured public sphere: percentage of european languages used by the EU accounts. Language of the tweet is already provided by Twitter API
    
    2) We could also look into how homogeneous the communication is. Although this is not exactly a normative demand regarding legitimacy, I can definitely imagine presenting a united public communication front would help maintain a good impression. We can look at this:
        1. Measuring document similarity by creating single documents out of all the tweets.
        2. Use of hashtags across the accounts
        
